{"jobID": "2783191901", "jobLocation": "Quincy_MA", "jobTitle": "VP, Service Delivery Management - Data Scientist", "companyRating": null, "companyInfo": {"Website": "www.statestreet.com", "Headquarters": "Boston, MA", "Size": "10000+ employees", "Founded": " 1792", "Type": " Company - Public (STT) ", "Industry": " Finance", "Revenue": " $10+ billion (USD) per year", "Competitors": " J.P. Morgan, BNY Mellon, Northern Trust"}, "estimatedSalary": null, "jobDescription": " State Street Global Technology Operations (GTO) \u2013 Process Excellence Office (PXO) is seeking a skilled and proven VP, Service Delivery Management \u2013 Data Scientist. The candidate will architect, design, develop, and implement multiple solutions within the PXO, including a unified and integrated big data ecosystem that ultimately supports the delivery of real-time advanced analytical and machine learning products and services to our clients.  This newly developed big data ecosystem must house raw and transformed data from various sources, maintain metadata repositories, enable faster delivery and consumption of data and insights, and continuously expand our offerings of new machine learning based products and services for our clients. The candidate will be required to have a proven track record of delivery of technically advanced solutions in support of multiple, simultaneous initiatives within the PXO which span multiple disciplines and business lines.  Specifically, the candidate will:  \u2022 Develop and deliver long-term strategic goals for the big data ecosystem (BDE) in line with PXO goals and objectives while ensuring alignment with advanced analytics and machine learning tools and techniques;  \u2022 Align the BDE strategy and implementation with the corporate IT/Omnia strategy, goals and objectives and ensuring continuity of this alignment with changes in technology, products and services;  \u2022 Create short-term tactical solutions and roadmaps to achieve long-term goals and objectives;  \u2022 Collaborate with other teams to create strategies and plans for data security, data quality, disaster recovery, and total business continuity for all data residing in the big data ecosystem;  \u2022 Collaborate with other teams to assess and determine a framework for managing data flow across the organization including mapping of data sources, data movement, and analytics, with the goal of ensuring data quality;  \u2022 Develop key components as needed to create acceptance criteria in order to guarantee the performance of implemented solutions;  \u2022 Integrate data science tools and techniques within the big data ecosystem, including but not limited to, data ingestion, transformation, model building and validation, visualization, and real-time data streaming;  \u2022 Continuously assess and deploy new big data technologies within the framework of the BDE with an aim to continuously improve our service delivery model;  \u2022 Work with our business partners and vendors to continuously evolve our BDE strategy and ensuring its relevancy and effectiveness remains at least at par with industry best practices and our competitors;  \u2022 Develop, manage, and grow a team of big data developers, coders, and implementers to ensure that the team can continue to exceed all the established goals and objectives for the BDE. Minimum Qualifications15+ years of proven related experience, including a minimum of 10 years\u2019 experience as a system, data, or information architectBS in IT/Computer Science, ideally with coursework in big data technologiesExperience with Cloudera big data technologies including Hadoop, Spark, Hive, Kafka, Pig, and Sqoop is vital for this position. This should include configuration and deployment of required components and other infrastructure in development, testing and production environmentsHands-on experience with data architecting and business requirements gathering/analysisDirect experience in implementing big data management processes, procedures, and decision supportStrong understanding of relational data structures, theories, principles, and practicesHands-on knowledge of enterprise repository tools, data modeling tools, data mapping tools, and data profiling toolsAbility to manage data and metadata migrationExperience with database platforms, including MySQL, Oracle, and MS SQL ServerProficiency and proven experience in Python programming language using SparkPreferred QualificationsAdditional proficiency and experience in programming languages including JAVA, J2EE, UI, and server side programming, and a good knowledge of web based technologies are a plusStrong communication and collaboration skills with the ability to work in a team environment (including a global work model) and to interact and influence peers, managers and senior leadersDemonstrated experience working in an environment managing multiple, concurrent deliverables with shifting priorities, demands, and timelinesResults oriented ownership mentalityStrong knowledge of both waterfall and agile SDLCs"}