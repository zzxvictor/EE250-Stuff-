{"jobID": "2824530527", "jobLocation": "Chicago_IL", "jobTitle": "Big Data Engineering Architect Consultant", "companyRating": "3.8", "companyInfo": {"Website": "www.accenture.com", "Headquarters": "Dublin, Ireland", "Size": "10000+ employees", "Founded": " 1989", "Type": " Company - Public (ACN) ", "Industry": " Unknown", "Revenue": " $10+ billion (USD) per year", "Competitors": " Cognizant Technology Solutions, EY, McKinsey & Company"}, "estimatedSalary": "97000", "jobDescription": "Job descriptionSchedule: Full-time  Organization: Analytics Business  Travel: 100% (Monday - Friday)  Position: Analytics Consulting \u2013 Big Data Engineering Architect Consultant  The digital revolution is changing everything. It\u2019s everywhere \u2013 transforming how we work and play. Are you reacting to the disruption each day or are you leading the way as a digital disrupter? Accenture Digital is driving these exciting changes and bringing them to life across 40 industries in more than 120 countries. At the forefront of digital, you\u2019ll create it, own it and make it a reality for clients looking to better serve their connected customers and operate always-on enterprises. Join us and become an integral part of our experienced digital team with the credibility, expertise and insight clients depend on.  Accenture Digital is powered by three practices \u2013Mobility, Interactive, and Analytics. As part of our Analytics practice, you\u2019ll deliver analytically-informed, issue-based solutions that help clients make faster, smarter decisions. You\u2019ll play a critical role in helping them tackle complex business issues. JOB DESCRIPTION Do you have a pulse on new technologies and a desire to change the way business gets done? Do you want to implement emerging solutions for some of the most successful companies around? If you answered yes to these questions and you are passionate about helping clients effectively manage enormous amounts of data to generate knowledge and value, then we want to meet you.  Data Engineers at the Consultant level will be responsible for architecture, design and implementation of Hadoop and NoSQL based full scale solutions that includes data acquisition, storage, transformation, security, data management and data analysis using these technologies. A solid understanding of infrastructure planning, scaling, design and operational considerations that are unique to Hadoop, NoSQL and other emerging data technologies is required. We are looking for candidates who have a broad set of technology skills across these areas and who can demonstrate an ability to identify and apply Hadoop and NoSQL solutions to challenges with data and provide better data solutions to industries.  Responsibilities include the following:  *Design and implement data management for Hadoop/NoSQL in a hybrid environment  *Design and implement large scale data architectures using Hadoop/NoSQL in a hybrid environment  * Data profiling and data analysis using emerging data technologies  * Design, implement and deploy data loaders to ingest data into Hadoop/NoSQL + Basic qualificationsBasic QualificationsBachelor's degree in Computer Science, Engineering, Technical Science or 3 years of IT/Programming experienceMinimum 1 year of architecting, implementing and successfully operationalizing large scale data solutions in production environments using Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, EMR, Kinesis, BigQuery, DataProc, Azure Data Lake etc.Minimum 1 year of architecting data and buildconing performant data models at scale for Hadoop/NoSQL ecosystem of data stores to support different business consumption patterns off a centralized data platformMinimum 1 year of Spark/MR/ETL processing, including Java, Python, Scala, Talend; for data analysis of production Big Data applicationsMinimum 1 year of architecting and industrializing data lakes or real-time platforms for an enterprise enabling business applications and usage at scaleMinimum 2 years designing and implementing relational data models working with RDBMS and understanding of the challenges in these environmentPreferred SkillsMinimum 1 year of experience implementing SQL on Hadoop solutions using tools like Presto, AtScale and othersMinimum 1 year of experience implementing large scale BI/Visualization solutions on Big Data platformsMinimum 1 year of experience implementing large scale secure cloud data solutions using AWS data and analytics services e.g. S3, EMR, RedshiftMinimum 1 year of experience implementing large scale secure cloud data solutions using Google data and analytics services e.g. BigQuery, DataProcMinimum 1 year of experience building data management (metadata, lineage, tracking etc.) and governance solutions for modern data platforms that use Hadoop and NoSQL on premise or on AWS, Google and Azure cloudMinimum 1 year of experience securing Hadoop/NoSQL based modern data platforms on-premise or on AWS, Google, Azure cloudMinimum 1 year of Re-architecting and rationalizing traditional data warehouses with Hadoop or NoSQL technologies on premise or transition to AWS, Google cloudsExperience implementing data wrangling and data blending solutions for enabling self-service solutions using tools such as Trifacta, Paxata1 year industry systems development and implementation experience OR Minimum of 2 years of data loading, acquisition, storage, transformation, and analysisMinimum 1 years of using Talend, Informatica like ETL tools within a Big Data environment to perform large scale metadata integrated data transformationMinimum 1 year of building Business Catalogs or Data Marketplaces on top of a Hybrid data platform containing Big Data technologiesResponsibilities include the following:"}