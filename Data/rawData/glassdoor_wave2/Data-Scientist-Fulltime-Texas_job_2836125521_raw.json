{"jobID": "2836125521", "jobLocation": "Dallas_TX", "jobTitle": "Big Data Engineer", "companyRating": null, "companyInfo": {"Website": "www.jamyinteractives.com", "Headquarters": "Herndon, VA", "Size": "1001 to 5000 employees", "Founded": " Unknown", "Type": " Company - Public", "Industry": " Unknown", "Revenue": " Unknown / Non-Applicable per year", "Competitors": " Unknown"}, "estimatedSalary": null, "jobDescription": "Big Data EngineerTravel: 100%Fulltime / Permanent PositionLocation: NATIONWIDEResponsibilitiesPerform data engineering, data modeling, and implementation of Big Data platform and analytic applicationsAnalyze latest Big Data Analytic technologies and their innovative applications in both business intelligence analysis and new service offerings; bring these insights and best practicesDevelop highly scalable and extensible Big Data platforms which enable collection, storage, modeling, and analysis of massive data sets including those from IoT and streaming dataConstruct big data pipelines, both real-time and batchImplement data access and processing frameworks.Support data users, data scientists, and analytic applicationsTechnical ExperienceCloud platform technologies such as Microsoft Azure, Amazon Web Services and Google Cloud. Hadoop distributions such as Cloudera, HortonworksBig Data Analytic frameworks and query tools such as Spark, Storm, Hive, HBase, Impala, HueStreaming data tools and techniques such as Kafka, AWS Kinesis, Microsoft Streaming Analytics, StreamSets, StreamAnalytixsETL (Extract-Transform-Load) tools such as Pentaho, Talend, Informatica); also experience with ELTInfrastructure setup using things like Kubernetes, DockerContinuous Integration and Continuous Development (CI/CD) Data Warehouse and DataMart design and implementationNoSQL environments such as MongoDB, CassandraMetadata management, data lineage, data governance, especially as related to Big DataStructured, Unstructured, Semi-Structured Data techniques and processesMinimum RequirementsOver 10 years of engineering and/or software development experience and demonstrable experience in a large organization.Experience should contain 5+ years of experience of data engineering (ETL and Big Data) pipelines, both real-time and batch5+ years of consulting experience desired3+ years of hands-on experience developing in Big Data Components/Frameworks including: Hadoop/HDFS, Spark, Storm, HBase, Pig, Hive, Scala, Kafka, PyScripts, Unix Shell scripts3+ years of hands-on experience configuring and implementing solutions on cloud platforms such as Azure, AWS, or Google Cloud.Experience with Continuous Integration / Continuous DevelopmentExperience in implementation of large and highly complex projectsHistory of working successfully with cross-functional engineering teams5+ years experience in one of the following business domains: Manufacturing, Cable/Telecom, Finance and Supply ChainDemonstrated ability to communicate highly technical concepts in business terms"}