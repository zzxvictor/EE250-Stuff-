{"jobID": "2723005105", "jobLocation": "Austin_TX", "jobTitle": "Data Engineer, IdentityAI", "companyRating": "4.8", "companyInfo": {"Website": "www.sailpoint.com", "Headquarters": "Austin, TX", "Size": "501 to 1000 employees", "Founded": " 2005", "Type": " Company - Public (SAIL) ", "Industry": " Information Technology", "Revenue": " $100 to $500 million (USD) per year", "Competitors": " Oracle, IBM, One World Identity"}, "estimatedSalary": "126000", "jobDescription": " At SailPoint, we do things differently. We understand that a fun-loving work environment can be highly motivating and productive. When smart people work on intriguing problems, and they enjoy coming to work each day, they accomplish great things together. With that philosophy, we\u2019ve assembled the best identity team in the world that is passionate about the power of identity.  As the fastest-growing, independent identity and access management (IAM) provider, SailPoint helps hundreds of global organizations securely and effectively deliver and manage user access from any device to data and applications residing in the data center, on mobile devices, and in the cloud. The company\u2019s innovative product portfolio offers customers an integrated set of core services including identity governance, provisioning, and access management delivered on-premises or from the cloud (IAM-as-a-service).  SailPoint has been voted a best place to work in Austin, 8 years in a row.  SailPoint is looking for a Data Engineer to build, maintain, monitor, and improve a real time scalable, fault tolerant, data processing pipeline, and productize machine learning algorithms, for a new cloud-based, multi-tenant, SaaS analytics product.  You will be integral in building this product and will be part of an agile team that is in startup mode. This is a unique opportunity to build something from scratch but have the backing of an organization that has the muscle to take it to market quickly, with a very satisfied customer base. ResponsibilitiesImplementing ETL processesMonitoring performance and advising any necessary infrastructure changesDefining data retention policiesProductizing and operationalizing machine learning algorithmsBe part of a team that is creating a brand-new product lineCollaborate with team members to help shape requirementsActively engage in technology discovery that can be applied to the productRequirements1+ year of data engineering or related experienceStrong Java and/or Scala experienceProficient understanding of distributed computing principlesAbility to solve any ongoing issues with operating the clusterExperience with integration of data from multiple data sourcesStrong knowledge of data cleaning and various ETL techniques and frameworksGreat communication skillsBS in Computer Science, or a related fieldPreferredProficiency with SparkExperience with Machine Learning using Mahout/Deeplearning4j/Spark MLExperience with stream processing using Spark Streaming/Storm/Beam/FlinkExperience with ElasticsearchExperience with messaging systems, such as Kafka or KinesisExperience with NoSQL databases, such as Redshift, Cassandra, DynamoDBCompensation and benefitsExperience a Small-company Atmosphere with Big-company BenefitsCompetitive pay, 401(k) and comprehensive medical, dental and vision plansRecharge your batteries with a flexible vacation policy and paid holidaysGrow with us with both technical and career growth opportunitiesEnjoy a healthy work-life balance with flexible hours, family-friendly company events and charitable work All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.  All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status."}