{"jobID": "2542153226", "jobLocation": "Chicago_IL", "jobTitle": "Principal Big Data Engineer", "companyRating": "3.2", "companyInfo": {"Website": "www.uptake.com", "Headquarters": "Chicago, IL", "Size": "501 to 1000 employees", "Founded": " 2014", "Type": " Company - Private", "Industry": " Information Technology", "Revenue": " Unknown / Non-Applicable", "Competitors": " Unknown"}, "estimatedSalary": "125000", "jobDescription": "What\u200b \u200bwe\u200b \u200bdo: Uptake harnesses the power of underutilized data to empower businesses to make informed  decisions. We partner with industry leaders to build a predictive analytics software platform that  grows smarter in one industry because of what we learn in another. The result is a powerful platform  that identifies problems before they happen, ultimately saving money, time and lives. What\u200b \u200byou\u2019ll\u200b \u200bdo: As a Big Data Engineer, you\u2019ll be responsible for the architecture of a complex analytics platform  that is already changing the way large industrial companies manage their assets. A Big Data  Engineer understands cutting-edge tools and frameworks, and is able to determine what the best  tools are for any given task. You will enable and work with our other developers to use cutting-edge  technologies in the fields of distributed systems, data ingestion and mapping, and machine learning,  to name a few. We also strongly encourage Engineers to tinker with existing tools, and to stay up to  date and test new technologies\u2014all with the aim of ensuring that our existing systems don\u2019t stagnate  or deteriorate. Responsibilities: As a Big Data Engineer, your responsibilities may include, but are not limited to, the following:  \u25cf Build a scalable Big Data Platform designed to serve many different use-cases and requirements  \u25cf Build a highly scalable framework for ingesting, transforming and enhancing data at web scale  \u25cf Develop data structures and processes using components of the Hadoop ecosystem such as Avro, Hive, Parquet, Impala, Hbase, Kudu, Tez, etc.  \u25cf Establish automated build and deployment pipelines  \u25cf Implement machine learning models that enable customers to glean hidden insights about their data Qualifications: \u25cf Bachelor's degree in Computer Science or related field  \u25cf 6+ years of system building experience  \u25cf 4+ years of programming experience using JVM based languages  \u25cf A passion for DevOps and an appreciation for continuous integration/deployment  \u25cf A passion for QA and an understanding that testing is not someone else\u2019s responsibility  \u25cf Experience automating infrastructure and build processes  \u25cf Outstanding programming and problem solving skills  \u25cf Strong passion for technology and building great systems  \u25cf Excellent communication skills and ability to work using Agile methodologies  \u25cf Ability to work quickly and collaboratively in a fast-paced, entrepreneurial environment  \u25cf Experience with service-oriented (SOA) and event-driven (EDA) architectures  \u25cf Experience using big data solutions in an AWS environment  \u25cf Experience with javascript or associated frameworks Preferred\u200b \u200bskills: We value these qualities, but they\u2019re not required for this role:  \u25cf Masters or Ph.D. in related field  \u25cf Experience as an open source contributor  \u25cf Experience with Akka, stream processing technologies and concurrency frameworks  \u25cf Experience with Data modeling  \u25cf Experience with Chef, Puppet, Ansible, Salt or equivalent  \u25cf Experience with Docker, Mesos and Marathon  \u25cf Experience with distributed messaging services, preferably Kafka  \u25cf Experience with distributed data processors, preferably Spark  \u25cf Experience with Angular, React, Redux, Immutable.js, Rx.js, Node.js or equivalent  \u25cf Experience with Reactive and/or Functional programming  \u25cf Understanding of Thrift, Avro or protocol buffers  If you think you would be a good fit for this role, and are interested in joining the best engineering team in Chicago, please provide your resume with a cover letter."}