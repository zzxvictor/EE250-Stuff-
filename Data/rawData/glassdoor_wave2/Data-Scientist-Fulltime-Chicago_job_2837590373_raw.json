{"jobID": "2837590373", "jobLocation": "Chicago_IL", "jobTitle": "Sr. Pentaho Big Data Engineer", "companyRating": "3.6", "companyInfo": {"Website": "www.cccis.com", "Headquarters": "Chicago, IL", "Size": "1001 to 5000 employees", "Founded": " 1980", "Type": " Company - Private", "Industry": " Information Technology", "Revenue": " $500 million to $1 billion (USD) per year", "Competitors": " Mitchell International, Solera Holdings"}, "estimatedSalary": "122000", "jobDescription": " Job Description SummaryThe Enterprise Analytics team at CCC has an open position for a Senior Pentaho Engineer. The team builds analytical solutions to provide insights to internal and external clients of CCC businesses in auto property damage and repair, medical claims and telematics data. Our solutions include analytical applications to identify the right claim cost to pay, claim cycle time processing, workflow productivity, financial performance, client and consumer satisfaction, and industry benchmarks.  Our data engineers use big data technology to create best-in-industry analytics capability. This position is an opportunity to use Pentaho with HDFS, Spark and Kafka technology for batch and streaming analytics. Data processes in Pentaho, if appropriate, include ingestion, standardization, metadata management, business rule curation, data enhancement, and statistical computation against data sources that include relational, XML, JSON, streaming, REST API, and unstructured data. Pentaho has provided a metadata injection layer for data ingestion across six SQLServer sources that will be leveraged for additional source ingestion.  Job Duties  The role has responsibility to understand, prepare, process and analyze data to drive operational, analytical and strategic business decisions. The Senior Pentaho Data Engineer will work closely with big data engineers, product owners, information engineers, data scientists, data modelers, infrastructure support and data governance positions. This role requires exceptional Pentaho developer skills who can mentor big data engineers in the appropriate solution architecture and Pentaho development practices. While you do not have to have big data skills, we are seeking Pentaho engineers who start with a base of programming skills but who also love to learn new tools and techniques in a big data landscape that is endlessly changing. QualificationsBuild end to end data flows from sources to fully curated and enhanced data sets. This can include the effort to locate and analyze source data, create data flows to extract, profile, and store ingested data, define and build data cleansing and imputation, map to a common data model, transform to satisfy business rules and statistical computations, and validate data content.Produce data building blocks, data models, and data flows for varying client demands such as dimensional data, data feeds, dashboard reporting, and data science research & explorationCreate, modify and maintain Pentaho code and complex SQL for BI/DW data flowsLearn to program in Spark and Python where Pentaho Spark co-generation is not adequateProduce automated tests of data flow componentsUse knowledge of the business to automate business-specific tests for data content qualityAutomate code deployment and promotionBuild automated orchestration with Pentaho and error handling for use by production operation teamsProvide technical expertise to diagnose errors from production support teamsCollaborate with team members in an Agile team (e.g., Scrum)Participate as both leader and learner in team tasks for architecture, design and analysisCoordinate within collocated on-site teams as well as with work plans for off-shore resourcesBachelor's Degree or Two Year Technical Program with a Programming SpecializationB.S. preferred in Computer Science, Information Systems, or related fieldMinimum two years of development experience with Pentaho with a preference for five years of ETL tool experience which can be from other tools such as Talend, DataStage, and InformaticaExperience with development of metadata-driven and fully parameterized Pentaho environmentsAdvanced SQL coding skills for data transformations, profiling, and query tasksUnix commands and scriptingExperience in agile environments such as scrum and KanbanPreference for experience in Hadoop fundamentals and architecture: HDFS, map-reduce, job performancePreference for open source big data skills in tools such as Hive, HBase, parquet, Spark SQLProgramming in a language such as Python (preferred), Scala, etc. Why Choose CCC  We promote a healthy work-life balance and offer generous benefit plans and resources designed with employee satisfaction in mind.  What we value is simple - customers, employee commitment, collaboration and clear communication.  We hire people who will embrace the company's goals and productively contribute in ways that help us serve the customer, innovate, and stay strong.  We make it a priority to keep employees healthy, happy and enriched. Healthy - Wellness programs and Perkspot/employee discount programHappy - Recognition programs, a confidential employee assistance program, and flexible work arrangements such as staggered start timesEnriched - Tuition reimbursement, training and learning programs, and leadership development opportunities Our corporate headquarters is located in downtown Chicago within the historic Merchandise Mart-a certified LEED (Leadership in Energy and Environmental Design) building.  CCC Information Services was ranked #17 in the Top 100 Digital Companies in Chicago in 2017 by Built In Chicago, an online community for digital technology entrepreneurs in Chicago. CCC is a great place to work. Join us!"}