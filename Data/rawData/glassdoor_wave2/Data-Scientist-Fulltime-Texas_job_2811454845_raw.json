{"jobID": "2811454845", "jobLocation": "Austin_TX", "jobTitle": "Data Engineer", "companyRating": "4.2", "companyInfo": {"Website": "www.thehtgroup.com", "Headquarters": "Austin, TX", "Size": "1 to 50 employees", "Founded": " 2001", "Type": " Company - Private", "Industry": " Business Services", "Revenue": " $10 to $25 million (USD) per year", "Competitors": " Unknown"}, "estimatedSalary": "90000", "jobDescription": "Overview We develop best-of-breed products monitoring products: Papertrail (Real Time Troubleshooting), AppOptics (Server, Infrastructure, and Application Performance Monitoring), Pingdom (Uptime and Digital experience monitoring and Loggly) (Log analysis Solution)  We are currently hiring Senior Data Engineers who enjoy working on large-scale distributed systems problems to build a metrics and monitoring solution used by thousands of customers.  We're a small team so everyone has the opportunity to have a big impact. We've built our platform out largely on Java8 Dropwizard services, a handful of Golang services and some C++ where performance is critical. We leverage Kafka as our main service bus, Cassandra for long term storage, Clickhouse for log storage, our in-house stream processing framework for online analytics, and we rely on Zookeeper as a core part of intra/inter-service coordination. Our data pipeline pushes millions of messages a second and 50TB of logs per day.  All team members, whether local or remote, commit code to GitHub, communicate over Slack and Google Hangouts, push code to production via our ChatOps bot, and run all production applications on AWS. We also use an array of best-of-breed SaaS applications to get code to production quickly and reliably. We are a team that is committed to a healthy work/life balance.  Papertrail, AppOptics, Pingdom and Loggly are wholly owned by SolarWinds Inc. so you get the benefits of a small startup with the backing of a big company, so there is no worry about the next round of funding. SolarWinds offers competitive bonus and matching 401k programs that create an attractive total compensation package. ResponsibilitiesBe a crucial contributor to the company's backend architectureBuild distributed systems using languages including Java 8, C++, Go, and RubyHelp drive the next generation of monitoring tools for cloud applicationsWork with massive datasets in a real-time distributed systemContinually improve availability, scalability, performance and automation of our servicesExplore and evaluate cutting-edge distributed systems technologies and practicesCome up with creative solutions to solve tough scalability and performance problemsWork with a distributed team of engineers across all layers of the productArchitect applications that leverage the latest capabilities provided by cloud technologiesQualifications The right candidate is adept at building scalable and highly-available systems in modern system languages. You are religious in using metrics to reason about the characteristics of an application, client library, or data store and use them to drive your decisions when shipping to production. You are a developer who appreciates well-written code and cares about the impact of your design decisions on the user experience. 4+ years of distributed systems experience with Java, Go or C++ Comfortable with using and reasoning about concurrency primitivesPassion for exploring emerging frameworks, libraries, technology stacksExperience with ZooKeeper, Dropwizard, Kafka, Cassandra or ElasticSearchUnderstand the importance of metric instrumentationExperience with building and consuming REST APIsExperience with highly-available (NoSQL) data storesComfortable debugging network, disk, performance bugs in complex distributed systemsExperience developing in Linux environments6+ years of relevant engineering experienceGit and Maven savvyComfortable with cloud-based deployment and remote teamsExtra Credit:On-call experience fire-fighting applications in productionAble to write applications that use SQL databasesExperience working with a remote teamExperience with AWS cloudHave built stream-processing applications using frameworks like Heron/Storm/SamzaHave worked with large time-series datasets"}