{"jobID": "2617185898", "jobLocation": "San_Francisco_CA", "jobTitle": "Machine Learning Engineer", "companyRating": "4.9", "companyInfo": {"Website": "www.homelight.com", "Headquarters": "San Francisco, CA", "Size": "51 to 200 employees", "Founded": " 2012", "Type": " Company - Private", "Industry": " Real Estate", "Revenue": " Unknown / Non-Applicable", "Competitors": " Unknown"}, "estimatedSalary": "146000", "jobDescription": " Who You Are  You\u2019re a data hound. You\u2019re comfortable pouring over billions of dynamic data points and bending them to your will. You\u2019ve leveraged the Apache stack to build persistent machine learning algorithms and you\u2019ve played inside Apache Hive data warehouses. You know what it takes to set up Apache \u201cbig data\u201d stacks and apply persistent machine learning models using Spark single-handedly.  As our first Machine Learning Engineer, you will own, along with our Data Engineers, the design, implementation, and optimization of our core data and data modeling products. You\u2019ll help us apply artificial intelligence to our market leading real estate agent matching algorithm, build our data warehouse infrastructure, and pioneer innovative business cases for using big data in real estate. What You\u2019ll Do: Create predictive models for real estate transactions using a dynamic dataset  Refine our agent matching algorithm to improve our core product  Design, model and build a large-scale data warehouse, using ETL and other related technologies.  Work closely with data scientists to optimize and productize machine learning models.  Work closely with engineering to implement and scale your machine learning models  Build infrastructure and systems for tracking data quality, usage, and consistency.  Design and develop new data products  Lead innovative ideas for solving challenges in real estate domain  Be the thought-leader for how we could use data and predictive algorithms to improve user experience and revenue potential from the AI products You Have: B.S. or M.S.. in Computer Science or a related field  3-5 years of experience in developing a data pipeline with custom ETL that accommodates data from multiple sources of data in multiple formats  Familiarity with at least one scripting language: R, Python, or Scala.  Experience using SQL to query databases.  Expertise in end to end big data architecture including the ability to design pipelines, design machine learning environment and work with data scientists to create persistent machine learning models.  Expertise in Hadoop ecosystem products and frameworks such as HDFS, Hbase, Sqoop/Flume/Kafka, Kudu.  Model production in Spark using MLlib  Application deployment using AWS, Virtual Machines, or Docker  Minimum 2 Years of Data engineering experience in Hadoop environment."}